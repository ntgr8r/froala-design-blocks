{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntgr8r/froala-design-blocks/blob/master/PyTorch_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "nU56A-FUOsoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvisio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3h1EAaaE1_wM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plan\n",
        "# Install PyTorch\n",
        "# Introduction to Tensors\n",
        "# GPU and You\n",
        "# Datasets and DataLoaders\n",
        "# Your first model\n",
        "  # Loading in data\n",
        "  # Setting an optimizer\n",
        "  # Training and testing\n",
        "  # Saving a checkpoint\n",
        "  # Saving a model\n",
        "  # Using Tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O7ZshRua_A-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "keL5Ue6n6ALj",
        "colab_type": "code",
        "outputId": "f364bf2f-5e0c-49a7-e6f3-76cbae50c0c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "# This is a tensor row then column\n",
        "x = torch.rand(4,4)\n",
        "print(\"My first PyTorch tensor: \", x)\n",
        "print(\"Tensor dimension: \", x.shape)\n",
        "\n",
        "# In math + physics tensors have more complicated definitions, but for\n",
        "# our purposes they're just numpy arrays that you can execute operations on\n",
        "# with a GPU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My first PyTorch tensor:  tensor([[0.6634, 0.9268, 0.9097, 0.2191],\n",
            "        [0.8996, 0.9523, 0.9412, 0.1074],\n",
            "        [0.0630, 0.8249, 0.9781, 0.2342],\n",
            "        [0.1591, 0.4465, 0.0053, 0.1909]])\n",
            "Tensor dimension:  torch.Size([4, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mavy0VJ26hNQ",
        "colab_type": "code",
        "outputId": "1d4c450b-264c-4912-8e82-f16c94e3d446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "cell_type": "code",
      "source": [
        "y = torch.rand(4,4)\n",
        "# You can perform all the operations you'd expect on tensors\n",
        "z = y.add(x)\n",
        "print(z)\n",
        "\n",
        "# Any mutation that mutates a tensor in place is post-fixed with a _\n",
        "# for xample x.copy_(y), x.t_() will change x\n",
        "y.add_(x)\n",
        "print(y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.1536, 1.0480, 1.1224, 0.6295],\n",
            "        [1.3789, 0.9750, 1.4775, 0.1956],\n",
            "        [0.2499, 1.1826, 1.3731, 0.5702],\n",
            "        [0.5278, 1.2348, 0.1687, 0.8151]])\n",
            "tensor([[1.1536, 1.0480, 1.1224, 0.6295],\n",
            "        [1.3789, 0.9750, 1.4775, 0.1956],\n",
            "        [0.2499, 1.1826, 1.3731, 0.5702],\n",
            "        [0.5278, 1.2348, 0.1687, 0.8151]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVvubUOc64cc",
        "colab_type": "code",
        "outputId": "d1bf633e-a6b9-4a7d-d729-579dca3ffee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# we can convert pytorch tensors to numpy arrays\n",
        "x = torch.randn(5)\n",
        "b = np.random.rand(5)\n",
        "print(type(x))\n",
        "print(type(b))\n",
        "print(x)\n",
        "\n",
        "y = x.numpy()\n",
        "print(type(y))\n",
        "print(y)\n",
        "\n",
        "# y still points to x\n",
        "x.add_(1)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([-0.6417,  0.3274,  0.0461, -0.6507,  0.5922])\n",
            "<class 'numpy.ndarray'>\n",
            "[-0.64170617  0.3274402   0.04614983 -0.65072805  0.59221715]\n",
            "tensor([0.3583, 1.3274, 1.0461, 0.3493, 1.5922])\n",
            "[0.35829383 1.3274403  1.0461498  0.34927195 1.5922172 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qOjVZH0M8pii",
        "colab_type": "code",
        "outputId": "e8b2b80b-ec76-4b6f-a8c4-450965a90d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# torch.FloatTensor which is a 32 float is the default type\n",
        "# Numpy default dtype is float64 while pytorch is float32\n",
        "\n",
        "# Can assign tensors to dtype and to devices\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  y = torch.ones_like(x, device=device)\n",
        "  x = x.to(device)\n",
        "  z = x + y\n",
        "  print(z)\n",
        "  print(z.to('cpu'))\n",
        "  print(type(z))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.8138, 1.4370, 0.6378, 2.1627, 3.6024], device='cuda:0')\n",
            "tensor([1.8138, 1.4370, 0.6378, 2.1627, 3.6024])\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g6Fmcigl9ixA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make a dataset object\n",
        "class CityData(Dataset):\n",
        "  def __init__(self, csv_file, transform=None):\n",
        "    self.city_data = pd.read_csv(csv_file)\n",
        "    self.transform = transform\n",
        "   \n",
        "  def __len__(self):\n",
        "    return len(self.city_data)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return self.city_data.iloc[[idx]].values\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmoMw6Ec-Woj",
        "colab_type": "code",
        "outputId": "8254331c-1dc5-4457-fea4-2cd662bf3b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "example_data = CityData(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "\n",
        "dataloader = DataLoader(example_data, batch_size=4, shuffle=True)\n",
        "\n",
        "print(len(dataloader.dataset))\n",
        "for i_batch, sampled_batch in enumerate(dataloader):\n",
        "  print(i_batch)\n",
        "  print(sampled_batch)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17000\n",
            "0\n",
            "tensor([[[-1.1915e+02,  3.4250e+01,  3.6000e+01,  3.5110e+03,  6.6400e+02,\n",
            "           2.9650e+03,  6.9500e+02,  4.0878e+00,  1.8680e+05]],\n",
            "\n",
            "        [[-1.2244e+02,  3.7750e+01,  4.6000e+01,  1.5190e+03,  2.9100e+02,\n",
            "           5.7300e+02,  2.8900e+02,  4.2667e+00,  3.3880e+05]],\n",
            "\n",
            "        [[-1.1733e+02,  3.3230e+01,  1.5000e+01,  1.9050e+03,  4.1600e+02,\n",
            "           1.2580e+03,  3.8800e+02,  3.3300e+00,  1.2790e+05]],\n",
            "\n",
            "        [[-1.2282e+02,  3.8390e+01,  2.2000e+01,  1.2880e+03,  2.4300e+02,\n",
            "           5.9300e+02,  2.2000e+02,  3.6250e+00,  2.3370e+05]]],\n",
            "       dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ivta5XCa-4ol",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now going to build a CNN to classify images\n",
        "# Why CNN\n",
        "# Quick overview of CNN\n",
        "# MNIST dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iNxC43rSVV5K",
        "colab_type": "code",
        "outputId": "503da10b-a936-4fde-db1c-59d0440286a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "cell_type": "code",
      "source": [
        "sample = datasets.MNIST('../data', train=True, download=True, transform=None)\n",
        "print(\"label: \", sample[0][1])\n",
        "sample[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label:  tensor(5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy\n/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/H\ntn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+\n/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/f\nv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y3\n5wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F37B5A82780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "qRh5w4LgVnVy",
        "colab_type": "code",
        "outputId": "ec459027-217f-4527-92fe-2fac67bf34bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        }
      },
      "cell_type": "code",
      "source": [
        "# Convert images to tensors\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "  return transforms.ToPILImage()(tensor)\n",
        "\n",
        "sample = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
        "tensor_to_image(sample[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy\n/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/H\ntn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+\n/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/f\nv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y3\n5wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F37ADF83A58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "ONZhljk_V7Ke",
        "colab_type": "code",
        "outputId": "115ea910-d3b9-4deb-89e1-b42931fee4b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        }
      },
      "cell_type": "code",
      "source": [
        "# For training we're going to normalize images so pixels are in range\n",
        "# [-1, 1]\n",
        "sample = datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "tensor_to_image(sample[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABI0lEQVR4nGOcwoAbMOGRo5UkCzKH\ny5CBIVaxTu6o4rPqFGTJJKE9h9V/MjDMYVgcInUtPRxZ5zyWAwyODAwMDAy/gm8zrGEzRLZz7iEG\nBgYGBj+ptw8uf//u3YTioKO2x9QZGFIXbcp6inADIzyE9K69d3x/F4dXLv05z+DKjtOfSSZn7uCU\nvMN56zt7HJLPGVFihY1Fi8Hv/HpsOhkYfrWrM2yaGoFdkiH/5s+/fmw4JBnOXP7OcOo8dsmpSwN5\nGMotsEnWPQjqf8zwff1PKB/J4X7KMSEMDAwRBVcx7PS+lno4nYHB71I1Qj2UZf2+Oo+BgcGle84j\nJGuYGBgYGDbpLeLKY2B4XL3mL7IcRCc7WzhDNdv3jkDUoEULPjRAftIEAFEvU+LJRQAHAAAAAElF\nTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F37ADF61438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "WyBCTzHxZICi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cYRWlQrYxKMc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Going to show two versions of the same basic network and training.\n",
        "# The first is to focus on the building blocks. Heavily commented.\n",
        "# The second shows you\n",
        "# how to do some useful things, like clean organization, saving and loading\n",
        "# and visualizing training.\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    \n",
        "    # Use super because if child using cooperative multiple inheritance\n",
        "    # then it sorts out the method resolution order. Which of the superclasses\n",
        "    # (parent classes) should __init__ be called on first\n",
        "    super(Network, self).__init__()\n",
        "    \n",
        "    # Tensor size going in\n",
        "    # (32, 1, 28, 28)\n",
        "    \n",
        "    # In channels, out channels, kernal size, stride\n",
        "    self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "    self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "    \n",
        "    # In features, out features\n",
        "    self.fc1 = nn.Linear(4*4*50, 500)\n",
        "    self.fc2 = nn.Linear(500, 10)\n",
        "   \n",
        "  def forward(self, x):\n",
        "    # Tensor shape going in\n",
        "    # (32, 1, 28, 28)\n",
        "    x = F.relu(self.conv1(x))\n",
        "    \n",
        "    # (32, 20, 24, 24)\n",
        "    # input, kernel size, stride\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "\n",
        "    # (32, 20, 12, 12)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    \n",
        "    # (32, 50, 8, 8)\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "\n",
        "    \n",
        "    # (32, 50, 4, 4)\n",
        "    # Flatten tensor\n",
        "    x = x.view(-1, 4*4*50)\n",
        "    \n",
        "    # (32, 800)\n",
        "    x = F.relu(self.fc1(x))\n",
        "\n",
        "    # (32, 500)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    # (32, 10)\n",
        "    # Why log softmax? Can be more numerically stable\n",
        "    # Subtraction instead of division\n",
        "    return F.log_softmax(x, dim=1)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iGwwb1Xc8oVO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
        "  \n",
        "  # By default models are initialized in train mode.\n",
        "  # Some layers like BatchNorm and Dropout have different\n",
        "  # behaviour in train and eval mode. Explicitly state \n",
        "  # what you're doing.\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    \n",
        "    # backward() function see a few lines down accumulates\n",
        "    # gradients so at the start of each minibatch you need\n",
        "    # to wipe them out so that you don't accumulate across\n",
        "    # mini batches\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(data)\n",
        "    \n",
        "    # negative log likelihood loss\n",
        "    # loss = -log(y)\n",
        "    # softmax assigns high confidence to a correct prediction\n",
        "    # NLL will be small, when low confidence to the correct class\n",
        "    # prediction NLL will be large\n",
        "    loss = F.nll_loss(predictions, target)\n",
        "    \n",
        "    # Compute sum of gradients\n",
        "    loss.backward()\n",
        "    # Parameter update based on current gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    if batch_idx % LOG_INTERVAL == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "      \n",
        "def test(model, device, test_loader, epoch):\n",
        "  # Means we don't use things like dropout and batchNorm\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  \n",
        "  # Don't apply gradients to these tensors\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      predictions = model(data)\n",
        "      \n",
        "      # Sum output instead of returning the average of the output as above.\n",
        "      # Use .item() to access one element tensor as a number. Over batch verusu\n",
        "      # whole set\n",
        "      test_loss += F.nll_loss(predictions, target, reduction='sum').item()\n",
        "      \n",
        "      # dim: dimension to reduce, and keepdim\n",
        "      # dim = 1 means over all the predictions.\n",
        "      # Keepdim = True means dim is retained\n",
        "      prediction = predictions.argmax(dim=1, keepdim=True)\n",
        "      \n",
        "      # compute elementwise equality\n",
        "      # view_as is view this tensor as the same as prediction - look into\n",
        "      correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
        "      \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VP_bJocbxDqu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "USE_CUDA = True if torch.cuda.is_available() else False\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "SEED = 2\n",
        "L_R = 0.01\n",
        "EPOCHS = 4\n",
        "BATCH_SIZE = 32\n",
        "LOG_INTERVAL = 10\n",
        "GLOBAL_ITER = 0\n",
        "\n",
        "def main():\n",
        "  \n",
        "  # Set seed so results are reproducible\n",
        "  torch.manual_seed(SEED)\n",
        "  \n",
        "  # num_workers = 0 => main process loading batches in\n",
        "  # num_workers = N > 0 => each worker loads a single batch and\n",
        "  # returns when done\n",
        "  # pin_memory speeds up transfer of loading images on cpu and then\n",
        "  # pushing them to GPU. Allocates samples in page-locked memory\n",
        "  kwargs = {'num_workers': 1, 'pin_memory': True} if USE_CUDA else {}\n",
        "  \n",
        "  \n",
        "  # swap color axis because\n",
        "  # numpy image: H x W x C\n",
        "  # torch image: C X H X W\n",
        "  # To Tensor normalizes to [0,1]\n",
        "  # we want to normalize to [-1, 1] so\n",
        "  # perform another normalization with mean and std of MNIST\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "      batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "  \n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "      batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "  model = Network().to(DEVICE)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=L_R)\n",
        "\n",
        "  for epoch in range(1, EPOCHS + 1):\n",
        "      train(model, DEVICE, train_loader, optimizer, epoch, LOG_INTERVAL)\n",
        "      test(model, DEVICE, test_loader, epoch)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N-_W1tHs1ITj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gj-SQoo6xIsd",
        "colab_type": "code",
        "outputId": "6e4e4d28-b9c5-432a-8aeb-24e8f36b24e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Add tensorboard\n",
        "from tensorboardcolab import TensorBoardColab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZnDqxE2msZbd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "USE_CUDA = True\n",
        "\n",
        "MNIST_MEAN = 0.1307\n",
        "MNIST_STD = 0.3081\n",
        "\n",
        "class Config:\n",
        "  \n",
        "  def __init__(self, **kwargs):\n",
        "    for key, value in kwargs.items():\n",
        "      setattr(self, key, value)\n",
        "\n",
        "\n",
        "model_config = Config(\n",
        "    cuda = True if torch.cuda.is_available() else False,\n",
        "    device = torch.device(\"cuda\" if USE_CUDA else \"cpu\"),\n",
        "    seed = 2,\n",
        "    lr = 0.01,\n",
        "    epochs = 4,\n",
        "    save_model = False,\n",
        "    batch_size = 32,\n",
        "    log_interval = 100\n",
        ")\n",
        "    \n",
        "class Trainer:\n",
        "  \n",
        "  def __init__(self, config):\n",
        "    \n",
        "    self.cuda = config.cuda\n",
        "    self.device = config.device\n",
        "    self.seed = config.seed\n",
        "    self.lr = config.lr\n",
        "    self.epochs = config.epochs\n",
        "    self.save_model = config.save_model\n",
        "    self.batch_size = config.batch_size\n",
        "    self.log_interval = config.log_interval\n",
        "    \n",
        "    self.globaliter = 0\n",
        "    self.tb = TensorBoardColab()\n",
        "    \n",
        "    torch.manual_seed(self.seed)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if self.cuda else {}\n",
        "\n",
        "    self.train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True,\n",
        "                     transform=transforms.Compose([\n",
        "                         transforms.ToTensor(),\n",
        "                         transforms.Normalize((MNIST_MEAN,), (MNIST_STD,))\n",
        "                     ])),\n",
        "        batch_size=self.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "    self.test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Normalize((MNIST_MEAN,), (MNIST_STD,))\n",
        "                         ])),\n",
        "        batch_size=self.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "    self.model = Network().to(self.device)\n",
        "    self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "      \n",
        "  def train(self, epoch):\n",
        "  \n",
        "    self.model.train()\n",
        "    for batch_idx, (data, target) in enumerate(self.train_loader):\n",
        "      \n",
        "      self.globaliter += 1\n",
        "      data, target = data.to(self.device), target.to(self.device)\n",
        "\n",
        "      self.optimizer.zero_grad()\n",
        "      predictions = self.model(data)\n",
        "\n",
        "      loss = F.nll_loss(predictions, target)\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "\n",
        "      if batch_idx % self.log_interval == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                  epoch, batch_idx * len(data), len(self.train_loader.dataset),\n",
        "                  100. * batch_idx / len(self.train_loader), loss.item()))\n",
        "        self.tb.save_value('Train Loss', 'train_loss', self.globaliter, loss.item())\n",
        "        torch.save(self.model.state_dict(), '{}_{}.pt'.format(self.globaliter, loss.item()))\n",
        "\n",
        "  def test(self, epoch):\n",
        "    self.model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for data, target in self.test_loader:\n",
        "        data, target = data.to(self.device), target.to(self.device)\n",
        "        predictions = self.model(data)\n",
        "\n",
        "        test_loss += F.nll_loss(predictions, target, reduction='sum').item()\n",
        "        prediction = predictions.argmax(dim=1, keepdim=True)\n",
        "        correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
        "\n",
        "      test_loss /= len(self.test_loader.dataset)\n",
        "      accuracy = 100. * correct / len(self.test_loader.dataset)\n",
        "\n",
        "      print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "          test_loss, correct, len(self.test_loader.dataset), accuracy))\n",
        "\n",
        "def main():\n",
        "  \n",
        "  trainer = Trainer(model_config)\n",
        "  \n",
        "  for epoch in range(1, trainer.epochs + 1):\n",
        "      trainer.train(epoch)\n",
        "      trainer.test(epoch)\n",
        "      trainer.tb.flush_line('train_loss')\n",
        "\n",
        "  if (trainer.save_model):\n",
        "      torch.save(trainer.model.state_dict(),\"mnist_cnn.pt\")\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jvxJvdZ7POeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OiS1ZYRfZTEN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Network().to(DEVICE)\n",
        "model.load_state_dict(torch.load(\"1001_0.012172117829322815.pt\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lvi3pl3F7ara",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm *.pt"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}